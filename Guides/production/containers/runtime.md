# 内存，CPU和GPU的运行时选项

默认情况下，容器没有资源限制，并且可以使用主机内核调度程序允许的尽可能多的给定资源。`Docker`提供了一些方法来控制容器可以使用多少内存或`CPU`，从而设置`docker run`命令的运行时配置标志。本节提供有关何时应设置此类限制的详细信息，以及设置这些限制的可能含义。

其中许多功能都要求您的内核支持`Linux`功能。要检查支持，可以使用 `docker info`命令。如果内核中的功能被禁用，则可能在输出末尾显示警告，如下所示：
```shell
WARNING: No swap limit support
```
请参阅操作系统的文档以启用它们。 [了解更多](https://docs.docker.com/install/linux/linux-postinstall/#your-kernel-does-not-support-cgroup-swap-limit-capabilities)。

## 内存
### 了解内存的风险
重要的是，不允许正在运行的容器占用过多的主机内存。在`Linux`主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它将抛出`OOME`或 `Out Of Memory Exception`，并开始终止进程​​以释放内存。任何进程都将遭到破坏，包括`Docker`和其他重要应用程序。如果杀死错误的进程，这可以有效地使整个系统瘫痪。

`Docker`试图通过调整`Docker`守护程序上的`OOM`优先级来减轻这些风险，从而使其比系统上其他进程更容易被杀死。容器的`OOM`优先级未调整。这使得杀死单个容器的可能性比杀死`Docker`守护进程或其他系统进程的可能性更大。您不应尝试通过`--oom-score-adj`在守护程序或容器上手动设置为负数或在容器上进行设置来规避这些安全措施`--oom-kill-disable`。

有关`Linux`内核的`OOM`管理的更多信息，请参阅[内存不足管理](https://www.kernel.org/doc/gorman/html/understand/understand016.html)。

您可以通过以下方法减轻由于`OOME`引起的系统不稳定的风险：

- 在将其投入生产之前，请执行测试以了解您的应用程序的内存要求。
- 确保您的应用程序仅在具有足够资源的主机上运行。
- 限制容器可以使用的内存量，如下所述。
- 在`Docker`主机上配置交换时要小心。交换的速度比内存慢，性能也较差，但可以提供缓冲以防系统内存不足。
- 考虑将容器转换为服务，并使用服务级别的约束和节点标签以确保应用程序仅在具有足够内存的主机上运行

### 限制容器的存储器访问
`Docker`可以强制执行硬性内存限制，即允许容器使用不超过给定数量的用户或系统内存；或软性限制，其可以允许容器使用所需数量的内存，除非满足某些条件，例如内核检测到主机上的内存不足或争用。当单独使用或设置多个选项时，其中一些选项会产生不同的效果。

大部分的选项取正整数，跟着一个后缀`b`，`k`， `m`，`g`，表示字节，千字节，兆字节或千兆字节。

| 选项	| 描述 |
| --- | --- |
| `-m` or `--memory=` |	容器可以使用的最大内存量。如果设置此选项，则最小允许值为4`m`（4 MB）。|
| `--memory-swap*` | 	允许此容器交换到磁盘的内存量。查看`--memory-swap`详细信息。 |
| `--memory-swappiness` | 	默认情况下，主机内核可以换出一定比例的容器使用的匿名页面。您可以设置`--memory-swappiness`一个介于0到100之间的值来调整此百分比。查看`--memory-swappiness`详细信息。 |
| `--memory-reservation` |	允许您指定一个小于`--memoryDocker`在主机上检测到争用或内存不足时激活的软限制。如果使用`--memory-reservation`，则必须将其设置为低于，`--memory`以使其具有优先权。因为这是一个软限制，所以不能保证容器不超过该限制。 |
| `--kernel-memory` |	容器可以使用的最大内核内存量。允许的最小值是4`m`。由于无法交换内核内存，因此内核内存不足的容器可能会阻塞主机资源，这可能会对主机和其他容器产生副作用。查看`--kernel-memory`详细信息。 |
| `--oom-kill-disable` |	默认情况下，如果发生内存不足（`OOM`）错误，则内核将终止容器中的进程。要更改此行为，请使用该`--oom-kill-disable`选项。仅在还设置了该`-m/--memory`选项的容器上禁用`OOM`杀手。如果`-m`未设置该标志，则主机可能会用完内存，内核可能需要终止主机系统的进程以释放内存。 |

有关一般`cgroup`和内存的更多信息，请参阅[`Memory Resource Controller`文档](https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt)。

### `--memory-swap`详细
`--memory-swap`是修饰符标志，仅在`--memory`同时设置时才有意义。使用交换允许容器在将可用的所有`RAM`用尽时将多余的内存需求写入磁盘。经常将内存交换到磁盘的应用程序会降低性能。

其设置可能会产生复杂的影响：

- 如果`--memory-swap`设置为正整数，那么这两个`--memory`和 `--memory-swap`必须设定。`--memory-swap`表示可以使用的内存和交换总量，并`--memory`控制非交换内存使用的总量。因此，如果`--memory="300m"`和`--memory-swap="1g"`，则容器可以使用`300m`的内存和`700m`（`1g - 300m`）交换。

- 如果`--memory-swap`将设置为`0`，则忽略该设置，并且该值被视为未设置。

- 如果`--memory-swap`将设置为与相同的值`--memory`，并且`--memory`将其设置为正整数，则该容器无权访问`swap`。请参阅 防止容器使用`swap`。

- 如果`--memory-swap`未设置，并且`--memory`已`--memory`设置，则在主机容器配置了交换内存的情况下，容器可以使用与设置一样多的交换。例如，如果`--memory="300m"`与`--memory-swap`没有设置，该容器可以在总的内存和交换使用600`m`。

- 如果`--memory-swap`将显式设置为`-1`，则允许容器使用无限制交换，最高不超过主机系统上可用的数量。

- 在容器内部，诸如`free`报告主机的可用交换之类的工具，而不是容器内部可用的工具，都在报告。不要依靠`free`或类似工具的输出来确定是否存在交换。

#### 防止容器使用交换
如果`--memory`和`--memory-swap`设置为相同的值，这将防止容器使用任何交换。这是因为`--memory-swap`是可以使用的组合内存和交换`--memory`的数量，而仅仅是可以使用的物理内存的数量。

### `--memory-swappiness`详细
- 值为0将关闭匿名页面交换。
- 值为100会将所有匿名页面设置为可交换。
- 默认情况下，如果不设置`--memory-swappiness`，则该值将从主机继承。

### `--kernel-memory`详细
内核内存限制以分配给容器的总内存表示。请考虑以下情形：

- 无限内存，无限内核内存：这是默认行为。
- 无限的内存，有限的内核内存：当所有`cgroup`所需的内存量大于主机上实际存在的内存量时，此方法适用。您可以将内核内存配置为永不遍历主机上可用的内存，并且需要更多内存的容器需要等待它。
- 内存有限，内核内存不受限制：整体内存有限，但内核内存不受限制。
- 内存有限，内核内存有限：限制用户和内核内存对于调试与内存相关的问题很有用。如果某个容器使用了意外数量的任一类型的内存，则它将用完内存而不会影响其他容器或主机。在此设置内，如果内核内存限制低于用户内存限制，则内核内存用完会导致容器出现	`OOM`错误。如果内核内存限制高于用户内存限制，则内核限制不会导致容器出现`OOM`。

当您打开任何内核内存限制时，主机将按进程跟踪“高水位标记”统计信息，因此您可以跟踪哪些进程（在这种情况下为容器）正在使用过多的内存。通过`/proc/<PID>/status`在主机上查看，可以按进程查看此信息。

## `CPU` 
默认情况下，每个容器对主机的`CPU`周期的访问都是不受限制的。您可以设置各种约束，以限制给定容器对主机`CPU`周期的访问。大多数用户使用并配置 默认的`CFS`调度程序。在`Docker 1.13`及更高版本中，您还可以配置 `realtime scheduler`。

### 配置默认的`CFS`调度
`CFS`是用于常规`Linux`进程的`Linux`内核`CPU`调度程序。几个运行时标志允许您配置对容器拥有的`CPU`资源的访问量。使用这些设置时，`Docker`会在主机上修改容器`cgroup`的设置。

| 选项 |	描述|
| --- | --- |
| `--cpus=<value>` |	指定一个容器可以使用多少可用的`CPU`资源。例如，如果主机有两个`CPU`，并且您设置了`--cpus="1.5"`，则可以保证容器最多容纳一半的`CPU`。这相当于设置`--cpu-period="100000"`和`--cpu-quota="150000"`。在`Docker 1.13`及更高版本中可用。 |
| `--cpu-period=<value>` |	指定`CPU CFS`调度程序周期，该周期与`--cpu-quota`一起使用。默认为100微秒。大多数用户不会更改默认设置。如果您使用`Docker 1.13`或更高版本，请改用`--cpus`。 |
| `--cpu-quota=<value>` |	在容器上设置`CPU CFS`配额。`--cpu-period`节流之前，容器被限制为每微秒数。这样就充当了有效的上限。如果您使用`Docker 1.13`或更高版本，请改用`--cpus`。 |
| `--cpuset-cpus` |	限制容器可以使用的特定`CPU`或内核。如果一个或多个`CPU`，则容器可以使用逗号分隔的列表或用连字符分隔的`CPU`范围。第一个`CPU`的编号为`0`。有效值可能是`0-3`（使用第一，第二，第三和第四CPU）或`1,3`（使用第二和第四CPU）。 |
| `--cpu-shares` |	将此标志设置为大于或小于默认值1024的值，以增加或减少容器的重量，并使其可以访问更多或更少的主机`CPU`周期。仅在限制`CPU`周期时才执行此操作。当有足够的`CPU`周期可用时，所有容器都会根据需要使用尽可能多的`CPU`。这样，这是一个软限制。`--cpu-shares`不会阻止以群集模式调度容器。它将容器`CPU`资源的优先级分配给可用的`CPU`周期。它不保证或保留任何特定的`CPU`访问权限。 |

如果您有1个`CPU`，则以下每个命令都会保证容器每秒最多占用50％的`CPU`。

`Docker 1.13及更高版本`：
```shell
docker run -it --cpus=".5" ubuntu /bin/bash
```
`Docker 1.12`及更低版本：
```shell
$ docker run -it --cpu-period=100000 --cpu-quota=50000 ubuntu /bin/bash
```

### 配置实时调度
在`Docker 1.13`及更高版本中，您可以将容器配置为使用实时调度程序，以执行无法使用`CFS`调度程序的任务。 在配置`Docker`守护程序或 配置单个容器之前，需要 确保正确配置了主机的内核。

> 警告：`CPU`调度和优先级划分是高级内核级功能。大多数用户不需要更改其默认值。错误地设置这些值可能会导致您的主机系统变得不稳定或无法使用。

#### 配置主机的内核
`CONFIG_RT_GROUP_SCHED`通过运行`zcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED`或检查文件是否存在来验证`Linux`内核中已启用该功能 `/sys/fs/cgroup/cpu.rt_runtime_us`。有关配置内核实时调度程序的指导，请参阅您的操作系统的文档。

#### 配置`DOCKER守`护程序
要使用实时调度程序运行容器，请运行`Docker`守护程序，并将该`--cpu-rt-runtime`标志设置为每个运行时间段为实时任务保留的最大微秒数。例如，使用默认时间段1000000微秒（1秒），此设置`--cpu-rt-runtime=950000`可确保使用实时调度程序的容器在每1000000微秒时间段内可以运行950000微秒，从而至少有50000微秒可用于非实时任务。要使该配置在使用的系统上永久存在 `systemd`，请参阅使用`systemd`控制和配置`Docker`。

#### 配置单个容器
使用启动容器时，可以传递多个标志来控制容器的`CPU`优先级`docker run`。请查阅操作系统的说明文件或ulimit命令以获取有关适当值的信息。

| 选项 |	描述 |
| --- | --- |
| `--cap-add=sys_nice` |	向容器授予该`CAP_SYS_NICE`功能，该功能允许容器提高过程`nice`值，设置实时调度策略，设置`CPU`亲和力以及其他操作。 |
| `--cpu-rt-runtime=<value>` |	容器可以在`Docker`守护程序的实时调度程序周期内以实时优先级运行的最大微秒数。您还需要`--cap-add=sys_nice`标志。 |
| `--ulimit rtprio=<value>` | 	容器允许的最大实时优先级。您还需要`--cap-add=sys_nice`标志。 |

以下示例命令在`debian:jessie` 容器上设置这三个标志中的每个标志。
```shell
$ docker run -it --cpu-rt-runtime=950000 \
                  --ulimit rtprio=99 \
                  --cap-add=sys_nice \
                  debian:jessie
```
如果内核或`Docker`守护程序配置不正确，则会发生错误。

## `GPU` 
### 访问`NVIDIA GPU` 
#### 先决条件
访问官方的`NVIDIA`驱动程序页面 ，下载并安装适当的驱动程序。完成后重新引导系统。

验证您的`GPU`是否正在运行并且可以访问。

#### 安装`NVIDIA-CONTAINER-RUNTIME`
按照`https://nvidia.github.io/nvidia-container-runtime/`上的说明进行操作，然后运行以下命令：
```shell
$ apt-get install nvidia-container-runtime
```
确保`nvidia-container-runtime-hook`可以从访问`$PATH`。
```shell
$ which nvidia-container-runtime-hook
```
重新启动`Docker`守护程序。

#### 公开`GPU`以供使用
`--gpus`启动容器访问`GPU`资源时，请包含该标志。指定要使用的`GPU`数量。例如：
```shell
$ docker run -it --rm --gpus all ubuntu nvidia-smi
```
公开所有可用的`GPU`，并返回类似于以下内容的结果：
```shell
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.130            	Driver Version: 384.130               	|
|-------------------------------+----------------------+----------------------+
| GPU  Name 	   Persistence-M| Bus-Id    	Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GRID K520       	Off  | 00000000:00:03.0 Off |                  N/A |
| N/A   36C	P0    39W / 125W |  	0MiB /  4036MiB |      0%  	Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU   	PID   Type   Process name                         	Usage  	|
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```
使用该`device`选项指定`GPU`。例如：
```shell
$ docker run -it --rm --gpus device=GPU-3a23c669-1f69-c64e-cf85-44e9b07e7a2a ubuntu nvidia-smi
```
公开该特定`GPU`。
```shell
$ docker run -it --rm --gpus device=0,2 nvidia-smi
```
公开第一个和第三个`GPU`。

> 注意：只有运行单个引擎的系统才能访问`NVIDIA GPU`。

#### 设置`NVIDIA`功能
您可以手动设置功能。例如，在`Ubuntu`上，您可以运行以下命令：
```shell
docker run --gpus 'all,capabilities=utility' --rm ubuntu nvidia-smi
```
这使得`utility`驱动程序具有将`nvidia-smi`工具添加到容器的功能。

可以通过环境变量在镜像中设置功能以及其他配置。有关有效变量的更多信息，请参见 `nvidia-container-runtime GitHub`页面。这些变量可以在`Dockerfile`中设置。

您还可以使用`CUDA`镜像来自动设置这些变量。有关更多信息，请参见`CUDA`镜像 `GitHub`页面。